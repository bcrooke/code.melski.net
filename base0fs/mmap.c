/*
 * Copyright (c) 1997-2007 Erez Zadok <ezk@cs.stonybrook.edu>
 * Copyright (c) 2001-2007 Stony Brook University
 *
 * For specific licensing information, see the COPYING file distributed with
 * this package, or get one from
 * ftp://ftp.filesystems.org/pub/fistgen/COPYING.
 *
 * This Copyright notice must be kept intact and distributed with all
 * fistgen sources INCLUDING sources generated by fistgen.
 */
/*
 * File: fistgen/templates/Linux-2.6/mmap.c
 */

#ifdef HAVE_CONFIG_H
# include <config.h>
#endif /* HAVE_CONFIG_H */
#ifdef FISTGEN
# include "fist_base0fs.h"
#endif /* FISTGEN */
#include "fist.h"
#include "base0fs.h"


#ifdef FIST_COUNT_WRITES
/* for counting writes in the middle vs. regular writes */
unsigned long count_writes = 0, count_writes_middle = 0;
#endif /* FIST_COUNT_WRITES */

#ifndef HAVE_WRITE_BEGIN
/* forward declaration of commit write and prepare write */
STATIC int base0fs_commit_write(file_t *file, page_t *page, unsigned from, unsigned to);
STATIC int base0fs_prepare_write(file_t *file, page_t *page, unsigned from, unsigned to);
#endif


STATIC int
base0fs_writepage(page_t *page, struct writeback_control *wbc)
{
	int err = -EIO;
	inode_t *inode;
	inode_t *lower_inode;
	page_t *lower_page;
	char *kaddr, *lower_kaddr;

	print_entry_location();

	inode = page->mapping->host;
	lower_inode = INODE_TO_LOWER(inode);

	/*
	 * writepage is called when shared mmap'ed files need to write
	 * their pages, while prepare/commit_write are called from the
	 * non-paged write() interface.  (However, in 2.3 the two interfaces
	 * share the same cache, while in 2.2 they didn't.)
	 *
	 * So we pretty much have to duplicate much of what commit_write does.
	 */

	/* find lower page (returns a locked page) */
	lower_page = grab_cache_page(lower_inode->i_mapping, page->index);
	if (!lower_page)
		goto out;

	/* get page address, and encode it */
	kaddr = (char *) kmap(page);
	lower_kaddr = (char*) kmap(lower_page);
	base0fs_encode_block(kaddr, lower_kaddr, PAGE_CACHE_SIZE, inode, inode->i_sb, page->index);
	/* if encode_block could fail, then return error */
	kunmap(page);
	kunmap(lower_page);

	/* call lower writepage (expects locked page) */
	err = lower_inode->i_mapping->a_ops->writepage(lower_page, wbc);

	/*
	 * update mtime and ctime of lower level file system
	 * base0fs' mtime and ctime are updated by generic_file_write
	 */
	lower_inode->i_mtime = lower_inode->i_ctime = CURRENT_TIME;

	page_cache_release(lower_page);	/* b/c grab_cache_page increased refcnt */

	if (err)
		ClearPageUptodate(page);
	else
		SetPageUptodate(page);
out:
	unlock_page(page);
	print_exit_status(err);
	return err;
}


/*
 * get one page from cache or lower f/s, return error otherwise.
 * returns unlocked, up-to-date page (if ok), with increased refcnt.
 */
page_t *
base0fs_get1page(file_t *file, int index)
{
	page_t *page;
	struct dentry *dentry;
	inode_t *inode;
	struct address_space *mapping;
	int err;

	print_entry_location();

	dentry = file->f_dentry; /* CPW: Moved below print_entry_location */
	inode = dentry->d_inode;
	mapping = inode->i_mapping;

	fist_dprint(8, "%s: read page index %d pid %d\n", __FUNCTION__, index, current->pid);
	if (index < 0) {
		printk("%s BUG: index=%d\n", __FUNCTION__, index);
		page = ERR_PTR(-EIO);
		goto out;
	}
	page = read_cache_page(mapping,
                               index,
                               (filler_t *) mapping->a_ops->readpage,
                               (void *) file);
	if (IS_ERR(page))
		goto out;
	wait_on_page_locked(page);
	if (!PageUptodate(page)) {
		lock_page(page);
		err = mapping->a_ops->readpage(file, page);
		if (err) {
			page = ERR_PTR(err);
			goto out;
		}
		wait_on_page_locked(page);
		if (!PageUptodate(page)) {
			page = ERR_PTR(-EIO);
			goto out;
		}
	}

out:
	print_exit_pointer(page);
	return page;
}


/*
 * get one page from cache or lower f/s, return error otherwise.
 * similar to get1page, but doesn't guarantee that it will return
 * an unlocked page.
 */
page_t *
base0fs_get1page_cached(file_t *file, int index)
{
	page_t *page;
	struct dentry *dentry;
	inode_t *inode;
	struct address_space *mapping;
	int err;

	print_entry_location();

	dentry = file->f_dentry; /* CPW: Moved below print_entry_location */
	inode = dentry->d_inode;
	mapping = inode->i_mapping;

	fist_dprint(8, "%s: read page index %d pid %d\n", __FUNCTION__, index, current->pid);
	if (index < 0) {
		printk("%s BUG: index=%d\n", __FUNCTION__, index);
		page = ERR_PTR(-EIO);
		goto out;
	}
	page = read_cache_page(mapping,
                               index,
                               (filler_t *) mapping->a_ops->readpage,
                               (void *) file);
	if (IS_ERR(page))
		goto out;

out:
	print_exit_pointer(page);
	return page;
}


/*
 * readpage is called from generic_page_read and the fault handler.
 * If your file system uses generic_page_read for the read op, it
 * must implement readpage.
 *
 * Readpage expects a locked page, and must unlock it.
 */
STATIC int
base0fs_do_readpage(file_t *file, page_t *page)
{
	int err = -EIO;
	struct dentry *dentry;
	file_t *lower_file = NULL;
	struct dentry *lower_dentry;
	inode_t *inode;
	inode_t *lower_inode;
	char *page_data;
	page_t *lower_page;
	char *lower_page_data;
	int real_size;

	print_entry_location();

	dentry = file->f_dentry; /* CPW: Moved below print_entry_location */
	if (FILE_TO_PRIVATE(file) == NULL) {
		err = -ENOENT;
		goto out_err;
	}
	lower_file = FILE_TO_LOWER(file);
	BUG_ON(!lower_file);	/* XXX: is this assertion right here? */
	lower_dentry = DENTRY_TO_LOWER(dentry);
	inode = dentry->d_inode;
	lower_inode = INODE_TO_LOWER(inode);

	fist_dprint(7, "%s: requesting page %lu from file %s\n", __FUNCTION__, page->index, dentry->d_name.name);

	MALLOC_PAGE_POINTERS(lower_pages, num_lower_pages);
	MALLOC_PAGEDATA_POINTERS(lower_pages_data, num_lower_pages);
	FOR_EACH_PAGE
                CURRENT_LOWER_PAGE = NULL;

	/* find lower page (returns a locked page) */
	FOR_EACH_PAGE {
		fist_dprint(8, "%s: Current page index = %lu\n", __FUNCTION__, (unsigned long) CURRENT_LOWER_PAGEINDEX);
		CURRENT_LOWER_PAGE = read_cache_page(lower_inode->i_mapping,
                                                     CURRENT_LOWER_PAGEINDEX,
                                                     (filler_t *) lower_inode->i_mapping->a_ops->readpage,
                                                     (void *) lower_file);
		if (IS_ERR(CURRENT_LOWER_PAGE)) {
			err = PTR_ERR(CURRENT_LOWER_PAGE);
			CURRENT_LOWER_PAGE = NULL;
			goto out_release;
		}
	}

	/*
	 * wait for the page data to show up
	 * (signaled by readpage as unlocking the page)
	 */
	FOR_EACH_PAGE {
		wait_on_page_locked(CURRENT_LOWER_PAGE);
		if (!PageUptodate(CURRENT_LOWER_PAGE)) {
			/*
			 * call readpage() again if we returned from wait_on_page with a
			 * page that's not up-to-date; that can happen when a partial
			 * page has a few buffers which are ok, but not the whole
			 * page.
			 */
			lock_page(CURRENT_LOWER_PAGE);
			err = lower_inode->i_mapping->a_ops->readpage(lower_file,
                                                                      CURRENT_LOWER_PAGE);
			if (err) {
				CURRENT_LOWER_PAGE = NULL;
				goto out_release;
			}
			wait_on_page_locked(CURRENT_LOWER_PAGE);
			if (!PageUptodate(CURRENT_LOWER_PAGE)) {
				err = -EIO;
				goto out_release;
			}
		}
	}

	/* map pages, get their addresses */
	page_data = (char *) kmap(page);
	FOR_EACH_PAGE
                CURRENT_LOWER_PAGEDATA = (char *) kmap(CURRENT_LOWER_PAGE);

	/* if decode_block could fail, then return error */
	err = 0;
	real_size = i_size_read(lower_inode) - ((loff_t)page->index << PAGE_CACHE_SHIFT);
	if (real_size <= 0)
		memset(page_data, 0, PAGE_CACHE_SIZE);
	else if (real_size < PAGE_CACHE_SIZE) {
		base0fs_decode_block(lower_page_data, page_data, real_size, inode, inode->i_sb, page->index);
		memset(page_data + real_size, 0, PAGE_CACHE_SIZE - real_size);
	} else
		base0fs_decode_block(lower_page_data, page_data, PAGE_CACHE_SIZE, inode, inode->i_sb, page->index);

	FOR_EACH_PAGE
                kunmap(CURRENT_LOWER_PAGE);
	kunmap(page);

out_release:
	FOR_EACH_PAGE
                if (CURRENT_LOWER_PAGE)
                        page_cache_release(CURRENT_LOWER_PAGE);	/* undo read_cache_page */

	FREE_PAGE_POINTERS(lower_pages, num_lower_pages);
	FREE_PAGEDATA_POINTERS(lower_pages_data, num_lower_pages);

out:
	if (err == 0)
		SetPageUptodate(page);
	else
		ClearPageUptodate(page);

out_err:
	print_exit_status(err);
	return err;
}


STATIC int
base0fs_readpage(file_t *file, page_t *page)
{
	int err;
	print_entry_location();

	err = base0fs_do_readpage(file, page);

	/*
	 * we have to unlock our page, b/c we _might_ have gotten a locked page.
	 * but we no longer have to wakeup on our page here, b/c UnlockPage does
	 * it
	 */
	unlock_page(page);

	print_exit_status(err);
	return err;
}

#ifndef HAVE_WRITE_BEGIN
STATIC int
base0fs_prepare_write(file_t *file, page_t *page, unsigned from, unsigned to)
{
	int err = 0;

	print_entry_location();

	/*
	 * we call kmap(page) only here, and do the kunmap
	 * and the actual downcalls, including unlockpage and uncache
	 * in commit_write.
	 */
	kmap(page);

	/* fast path for whole page writes */
	if (from == 0 && to == PAGE_CACHE_SIZE)
		goto out;
	/* read the page to "revalidate" our data */
	/* call the helper function which doesn't unlock the page */
	if (!PageUptodate(page))
		err = base0fs_do_readpage(file, page);

out:
	print_exit_status(err);
	return err;
}



STATIC int
base0fs_commit_write(file_t *file, page_t *page, unsigned from, unsigned to)
{
        int err = -ENOMEM;
        inode_t *inode;
        inode_t *lower_inode;
        page_t *lower_page;
        file_t *lower_file = NULL;
        loff_t pos;
        unsigned bytes = to - from;
        unsigned lower_from, lower_to, lower_bytes;

        print_entry_location();

        inode = page->mapping->host; /* CPW: Moved below print_entry_location */
        lower_inode = INODE_TO_LOWER(inode);

        BUG_ON(!file);
        /*
         * here we have a kmapped page, with data from the user copied
         * into it.  we need to encode_block it, and then call the lower
         * commit_write.  We also need to simulate same behavior of
         * generic_file_write, and call prepare_write on the lower f/s first.
         */
#ifdef FIST_COUNT_WRITES
        count_writes++;
#endif /* FIST_COUNT_WRITES */

        /* this is append and/or extend -- we can't have holes so fill them in */
        if (page->index > (i_size_read(lower_inode) >> PAGE_CACHE_SHIFT)) {
                page_t *tmp_page;
                int index;
                for (index = i_size_read(lower_inode) >> PAGE_CACHE_SHIFT; index < page->index; index++) {
                        tmp_page = base0fs_get1page(file, index);
                        if (IS_ERR(tmp_page)) {
                                err = PTR_ERR(tmp_page);
                                goto out;
                        }
                        kmap(tmp_page);

                        /* zero out the contents of the page at the appropriate offsets */
                        memset((char*)page_address(tmp_page) + (i_size_read(inode) & ~PAGE_CACHE_MASK), 0, PAGE_CACHE_SIZE - (i_size_read(inode) & ~PAGE_CACHE_MASK));
                        if (!(err = base0fs_prepare_write(file, tmp_page, 0, PAGE_CACHE_SIZE)))
                                err = base0fs_commit_write(file, tmp_page, 0, PAGE_CACHE_SIZE);
                        kunmap(tmp_page);

                        page_cache_release(tmp_page);
                        if (err < 0)
                                goto out;
                        if (need_resched())
                                schedule();

                }
        }

        if (FILE_TO_PRIVATE(file) != NULL)
                lower_file = FILE_TO_LOWER(file);
        BUG_ON(!lower_file);	/* XXX: is this assertion right here? */

        lock_inode(lower_inode);
        /* find lower page (returns a locked page) */
        lower_page = grab_cache_page(lower_inode->i_mapping, page->index);
        if (!lower_page)
                goto out_up;
        kmap(lower_page);

#if FIST_ENCODING_BLOCKSIZE > 1
#error encoding_blocksize greater than 1 is not yet supported
#endif /* FIST_ENCODING_BLOCKSIZE > 1 */

        lower_from = from & (~(FIST_ENCODING_BLOCKSIZE - 1));
        lower_to = ((to + FIST_ENCODING_BLOCKSIZE - 1) & (~(FIST_ENCODING_BLOCKSIZE - 1)));
        if (((loff_t)page->index << PAGE_CACHE_SHIFT) + to > i_size_read(lower_inode)) {

                /*
                 * if this call to commit_write had introduced holes and the code
                 * for handling holes was invoked, then the beginning of this page
                 * must be zeroed out
                 * zero out bytes from 'size_of_file%pagesize' to 'from'.
                 */
                if ((lower_from - (i_size_read(inode) & ~PAGE_CACHE_MASK)) > 0)
                        memset((char*)page_address(page) + (i_size_read(inode) & ~PAGE_CACHE_MASK), 0, lower_from - (i_size_read(inode) & ~PAGE_CACHE_MASK));

        }
        lower_bytes = lower_to - lower_from;

        /* call lower prepare_write */
        err = -EINVAL;
        if (lower_inode->i_mapping &&
            lower_inode->i_mapping->a_ops &&
            lower_inode->i_mapping->a_ops->prepare_write)
                err = lower_inode->i_mapping->a_ops->prepare_write(lower_file,
                                                                   lower_page,
                                                                   lower_from,
                                                                   lower_to);
        if (err)
                /* don't leave locked pages behind, esp. on an ENOSPC */
                goto out_unlock;

        fist_dprint(8, "%s: encoding %d bytes\n", __FUNCTION__, lower_bytes);
        base0fs_encode_block((char *) page_address(page) + lower_from, (char*) page_address(lower_page) + lower_from, lower_bytes, inode, inode->i_sb, page->index);
        /* if encode_block could fail, then goto unlock and return error */

        /* call lower commit_write */
        err = lower_inode->i_mapping->a_ops->commit_write(lower_file,
                                                          lower_page,
                                                          lower_from,
                                                          lower_to);

        if (err < 0)
                goto out_unlock;

        err = bytes;	/* convert error to no. of bytes */

        inode->i_blocks = lower_inode->i_blocks;
        /* we may have to update i_size */
        pos = ((loff_t)page->index << PAGE_CACHE_SHIFT) + to;
        if (pos > i_size_read(inode))
                i_size_write(inode, pos);

        /*
         * update mtime and ctime of lower level file system
         * base0fs' mtime and ctime are updated by generic_file_write
         */
        lower_inode->i_mtime = lower_inode->i_ctime = CURRENT_TIME;

        mark_inode_dirty_sync(inode);

out_unlock:
        kunmap(lower_page);
        unlock_page(lower_page);
        page_cache_release(lower_page);
        kunmap(page);		/* kmap was done in prepare_write */
out_up:
        unlock_inode(lower_inode);
out:
        /* we must set our page as up-to-date */
        if (err < 0)
                ClearPageUptodate(page);
        else
                SetPageUptodate(page);
        print_exit_status(err);
        return err;			/* assume all is ok */
}

#else  /* HAVE_WRITE_BEGIN */

int base0fs_write_begin(struct file *file, struct address_space *mapping,
			loff_t pos, unsigned len, unsigned flags,
			struct page **pagep, void **fsdata)
{
    *fsdata = (void *) (long) flags;
    return simple_write_begin(file, mapping, pos, len, flags, pagep, fsdata);
}

int base0fs_write_end(struct file *file, struct address_space *mapping,
			loff_t pos, unsigned len, unsigned copied,
			struct page *page, void *fsdata)
{
    struct inode *inode = page->mapping->host;
    struct inode *lower_inode = INODE_TO_LOWER(mapping->host);
    struct file  *lower_file  = FILE_TO_LOWER(file);
    struct address_space *lower_mapping = lower_inode->i_mapping;
    unsigned char *lower_data, *data;
    int err = 0;
    struct page *lower_page;
    void *lower_fsdata = 0;
    unsigned from = pos & (PAGE_CACHE_SIZE - 1);
    loff_t size = ((loff_t)page->index << PAGE_CACHE_SHIFT) + from + len;
    ADDRESS_SPACE_OPS_T *aops;

    if (!PageUptodate(page)) {
        SetPageUptodate(page);
    }
    if (size > inode->i_size) {
        i_size_write(inode, size);
    }
    set_page_dirty(page);

    aops = (ADDRESS_SPACE_OPS_T *) lower_mapping->a_ops;
    if (!aops || !aops->write_begin || !aops->write_end) {
        err = -EINVAL;
        goto out_up;
    }

    err = aops->write_begin(lower_file, lower_mapping,
            pos, len, (unsigned) (long) fsdata, &lower_page, &lower_fsdata);
    if (err) {
        goto out_up;
    }

    lower_data = kmap(lower_page);
    data       = kmap(page);
    memcpy(lower_data + from, data + from, len);
    kunmap(page);
    kunmap(lower_page);

    flush_dcache_page(lower_page);
    mark_page_accessed(lower_page);

    err = aops->write_end(lower_file, lower_mapping,
            pos, len, copied, lower_page, lower_fsdata);

out_up:
    unlock_page(page);
    page_cache_release(page);

    return err;
}

#endif /* end HAVE_WRITE_BEGIN */

STATIC sector_t
base0fs_bmap(struct address_space *mapping, sector_t block)
{
        int err = 0;
        inode_t *inode;
        inode_t *lower_inode;

        print_entry_location();

        inode = (inode_t *) mapping->host;
        lower_inode = INODE_TO_LOWER(inode);

        if (lower_inode->i_mapping->a_ops->bmap)
                err = lower_inode->i_mapping->a_ops->bmap(lower_inode->i_mapping, block);
        print_exit_location();
        return err;
}


/*
 * This function is copied verbatim from mm/filemap.c.
 * XXX: It should be simply moved to some header file instead -- bug Al about it!
 */
#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17)
static inline int sync_page(struct page *page)
#else
static inline void sync_page(struct page *page)
#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17) */
{
        struct address_space *mapping = page->mapping;

#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17)
        if (mapping && mapping->a_ops && mapping->a_ops->sync_page)
                return mapping->a_ops->sync_page(page);
        return 0;
#else
        if (mapping && mapping->a_ops && mapping->a_ops->sync_page)
                mapping->a_ops->sync_page(page);
        return;
#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17) */
}


/*
 * XXX: we may not need this function if not FIST_FILTER_DATA.
 * FIXME: for FIST_FILTER_SCA, get all lower pages and sync them each.
 * XXX: address_space_operations.sync_page returns void in .17 and up.
 *      how do you handle the -ENOMEM error?
 */
#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17)
STATIC int
#else
STATIC void
#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17) */
base0fs_sync_page(page_t *page)
{
        int err = 0;
        inode_t *inode;
        inode_t *lower_inode;
        page_t *lower_page;

        print_entry_location();

        inode = page->mapping->host; /* CPW: Moved below print_entry_location */
        lower_inode = INODE_TO_LOWER(inode);

        /* find lower page (returns a locked page) */
        lower_page = grab_cache_page(lower_inode->i_mapping, page->index);
        if (!lower_page) {
                err = -ENOMEM;
                goto out;
        }
#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17)
        err = sync_page(lower_page);
#else
        sync_page(lower_page);
#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17) */

        unlock_page(lower_page);	/* b/c grab_cache_page locked it */
        page_cache_release(lower_page);	/* b/c grab_cache_page increased refcnt */

out:
        print_exit_status(err);
#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17)
        return err;
#else
        return;
#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17) */
}


/*
 * Local variables:
 * c-basic-offset: 4
 * End:
 */
